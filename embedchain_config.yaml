llm:
  provider: ollama
  config:
    model: internlm/internlm2.5:1.8b-chat
    temperature: 0.5
    top_p: 1
    stream: true
    base_url: 'http://localhost:11434'
embedder:
  provider: ollama
  config:
    model: znbang/bge:small-en-v1.5-q8_0
    base_url: http://localhost:11434
vectordb:
  provider: chroma
  config:
    collection_name: 'my-collection'
    dir: db
    allow_reset: true
